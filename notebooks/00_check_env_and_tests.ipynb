{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a1f919",
   "metadata": {},
   "source": [
    "# 00 — Environment check and smoke/consistency tests (Windows-friendly)\n",
    "\n",
    "This notebook validates your environment (hardware, drivers, libraries, providers), runs quick smoke and optional consistency tests, and generates reusable diagnostics artifacts.\n",
    "\n",
    "It does not abort if something is missing; it records status and continues. Outputs are written under `reports/` for later use by other notebooks.\n",
    "\n",
    "Artifacts:\n",
    "- reports/env_report.json, reports/env_report.md\n",
    "- reports/providers_status.csv\n",
    "- reports/consistency_quickcheck.json (if models exist)\n",
    "- reports/00_status.json\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3214d4ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T23:05:34.739226Z",
     "start_time": "2025-08-12T23:05:26.212813Z"
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Section B1 — Run environment collection and write env_report.json/md\n",
    "from utils.env_report import gather_env_info, save_env_report\n",
    "\n",
    "# Detect project root (assume this notebook is in notebooks/)\n",
    "ROOT = Path(__file__).resolve().parent.parent if '__file__' in globals() else Path(os.getcwd()).parent\n",
    "REPORTS = ROOT / 'reports'\n",
    "METRICS = ROOT / 'metrics'\n",
    "ASSETS = ROOT / 'tests' / 'assets'\n",
    "ONNX_DIR = ROOT / 'models_saved' / 'onnx'\n",
    "PT_DIR = ROOT / 'models_saved' / 'pytorch'\n",
    "OV_DIR = ROOT / 'models_saved' / 'openvino_ir'\n",
    "\n",
    "REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "METRICS.mkdir(parents=True, exist_ok=True)\n",
    "ASSETS.mkdir(parents=True, exist_ok=True)\n",
    "ONNX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "info = gather_env_info(ROOT)\n",
    "save_env_report(info, str(REPORTS / 'env_report.json'), str(REPORTS / 'env_report.md'))\n",
    "print('Saved reports/env_report.json and reports/env_report.md')\n",
    "print('Providers:', info.get('onnxruntime', {}).get('available'))\n",
    "print('GPU(s):', info.get('nvidia'))\n",
    "print('OpenVINO devices:', info.get('openvino', {}).get('available'))\n",
    "print('Write permissions:', info.get('write_permissions'))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reports/env_report.json and reports/env_report.md\n",
      "Providers: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "GPU(s): {'gpu_name': 'NVIDIA GeForce RTX 4080 Laptop GPU', 'driver_version': '580.97'}\n",
      "OpenVINO devices: ['CPU', 'GPU', 'NPU']\n",
      "Write permissions: {'metrics': True, 'reports': True}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c3f7c39d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T23:05:35.074170Z",
     "start_time": "2025-08-12T23:05:34.776226Z"
    }
   },
   "source": [
    "# Section C1 — PyTorch, ONNX, OpenVINO availability and basic checks\n",
    "from utils.env_report import check_pytorch, check_onnxruntime, check_openvino\n",
    "\n",
    "print('PyTorch:', check_pytorch())\n",
    "print('ONNX Runtime:', check_onnxruntime())\n",
    "print('OpenVINO:', check_openvino())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: {'installed': True, 'version': '2.8.0+cu129', 'cuda_available': True, 'cuda_device_count': 1, 'cudnn': 91002}\n",
      "ONNX Runtime: {'available': ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'], 'session_cpu': True, 'session_cuda': True, 'error': None}\n",
      "OpenVINO: {'available': ['CPU', 'GPU', 'NPU'], 'error': None}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "dbf2e624",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T23:05:35.098259Z",
     "start_time": "2025-08-12T23:05:35.083398Z"
    }
   },
   "source": [
    "# Section C2 — Check write permissions for all relevant folders\n",
    "from utils.env_report import check_write_permissions\n",
    "\n",
    "folders = [REPORTS, METRICS, ASSETS, ONNX_DIR, PT_DIR, OV_DIR]\n",
    "perms = {str(f): check_write_permissions(f) for f in folders}\n",
    "print('Write permissions:', perms)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write permissions: {'C:\\\\Users\\\\padul\\\\OneDrive\\\\Universidad\\\\Doctorado\\\\Desarrollo\\\\federated-lab-multihw\\\\reports': True, 'C:\\\\Users\\\\padul\\\\OneDrive\\\\Universidad\\\\Doctorado\\\\Desarrollo\\\\federated-lab-multihw\\\\metrics': True, 'C:\\\\Users\\\\padul\\\\OneDrive\\\\Universidad\\\\Doctorado\\\\Desarrollo\\\\federated-lab-multihw\\\\tests\\\\assets': True, 'C:\\\\Users\\\\padul\\\\OneDrive\\\\Universidad\\\\Doctorado\\\\Desarrollo\\\\federated-lab-multihw\\\\models_saved\\\\onnx': True, 'C:\\\\Users\\\\padul\\\\OneDrive\\\\Universidad\\\\Doctorado\\\\Desarrollo\\\\federated-lab-multihw\\\\models_saved\\\\pytorch': True, 'C:\\\\Users\\\\padul\\\\OneDrive\\\\Universidad\\\\Doctorado\\\\Desarrollo\\\\federated-lab-multihw\\\\models_saved\\\\openvino_ir': True}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "e58cd3b5",
   "metadata": {},
   "source": [
    "## Section D — Smoke tests\n",
    "We'll run a tiny end-to-end inference with ORT (CPU and optional CUDA) and OpenVINO CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "8d78a3a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T23:05:35.140851Z",
     "start_time": "2025-08-12T23:05:35.132652Z"
    }
   },
   "source": [
    "# Section D1 — Run basic model import and ONNX export checks\n",
    "from utils.env_report import test_model_import_and_export\n",
    "\n",
    "results = test_model_import_and_export(ONNX_DIR)\n",
    "print('Model import/export results:', results)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model import/export results: {'ok': True, 'onnx_path': 'C:\\\\Users\\\\padul\\\\OneDrive\\\\Universidad\\\\Doctorado\\\\Desarrollo\\\\federated-lab-multihw\\\\models_saved\\\\onnx\\\\tiny_envcheck.onnx', 'sha256': '0103917f5f74cb7c38269a77d640959e71f4004fd3b2725eb5d69721eff87461'}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "9c8538c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T23:05:35.346950Z",
     "start_time": "2025-08-12T23:05:35.198379Z"
    }
   },
   "source": [
    "# Section D2 — Run basic inference and consistency checks\n",
    "from utils.env_report import test_inference_consistency\n",
    "\n",
    "consistency = test_inference_consistency(ONNX_DIR)\n",
    "print('Inference consistency:', consistency)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference consistency: {'ok': True, 'cpu_ok': True, 'cuda_ok': True, 'consistent': True, 'cpu_error': None, 'cuda_error': None}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "7c088b9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T23:05:35.397965Z",
     "start_time": "2025-08-12T23:05:35.364168Z"
    }
   },
   "source": [
    "# Section F — Global Pass/Fail summary and 00_status.json\n",
    "from pathlib import Path\n",
    "import json, csv\n",
    "\n",
    "status = {\n",
    "    'providers_ok': False,\n",
    "    'gpu_cuda_ok': False,\n",
    "    'write_permissions_ok': False,\n",
    "    'npu_detected': False,\n",
    "    'consistency_ok': None,\n",
    "}\n",
    "\n",
    "# Load env report for write permissions and OV devices\n",
    "try:\n",
    "    env = json.loads(Path(f'{REPORTS}/env_report.json').read_text(encoding='utf-8'))\n",
    "    status['write_permissions_ok'] = bool(\n",
    "        env.get('write_permissions', {}).get('reports') and env.get('write_permissions', {}).get('metrics'))\n",
    "    ov_devs = env.get('openvino', {}).get('available', [])\n",
    "    status['npu_detected'] = 'NPU' in (ov_devs or [])\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Providers status from CSV\n",
    "try:\n",
    "    rows = list(csv.reader(open(f'{REPORTS}/providers_status.csv', newline='', encoding='utf-8')))\n",
    "    hdr = rows[0];\n",
    "    data = rows[1:]\n",
    "    idx = {name: i for i, name in enumerate(hdr)}\n",
    "\n",
    "\n",
    "    def find(backend, prov):\n",
    "        for r in data:\n",
    "            if r[idx['backend']] == backend and r[idx['provider_or_device']] == prov:\n",
    "                return r\n",
    "        return None\n",
    "\n",
    "\n",
    "    ort_cpu = find('ORT', 'CPU')\n",
    "    ov_cpu = find('OpenVINO', 'CPU')\n",
    "    status['providers_ok'] = bool(\n",
    "        ort_cpu and ov_cpu and (ort_cpu[idx['test_infer_ok']] == 'True' or ort_cpu[idx['test_infer_ok']] == True) and (\n",
    "                ov_cpu[idx['test_infer_ok']] == 'True' or ov_cpu[idx['test_infer_ok']] == True))\n",
    "    ort_cuda = find('ORT', 'CUDA')\n",
    "    if ort_cuda:\n",
    "        status['gpu_cuda_ok'] = bool(ort_cuda[idx['test_infer_ok']] == 'True' or ort_cuda[idx['test_infer_ok']] == True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Consistency quickcheck\n",
    "cc_path = Path(f'{REPORTS}/consistency_quickcheck.json')\n",
    "if cc_path.exists():\n",
    "    try:\n",
    "        cc = json.loads(cc_path.read_text(encoding='utf-8'))\n",
    "        status['consistency_ok'] = bool(cc.get('consistency_ok'))\n",
    "    except Exception:\n",
    "        status['consistency_ok'] = False\n",
    "\n",
    "Path(f'{REPORTS}/00_status.json').write_text(json.dumps(status, indent=2), encoding='utf-8')\n",
    "\n",
    "# Render human summary\n",
    "mk = []\n",
    "mk.append('## Summary\\n')\n",
    "mk.append(f\"- Providers (ORT CPU + OV CPU): {'✅' if status['providers_ok'] else '❌'}\\n\")\n",
    "mk.append(f\"- GPU CUDA (if present): {'✅' if status['gpu_cuda_ok'] else '❌'}\\n\")\n",
    "mk.append(f\"- Write permissions (reports + metrics): {'✅' if status['write_permissions_ok'] else '❌'}\\n\")\n",
    "mk.append(f\"- NPU detected: {'✅' if status['npu_detected'] else '❌'}\\n\")\n",
    "if status['consistency_ok'] is not None:\n",
    "    mk.append(f\"- Consistency quickcheck: {'✅' if status['consistency_ok'] else '❌'}\\n\")\n",
    "print(''.join(mk))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Summary\n",
      "- Providers (ORT CPU + OV CPU): ✅\n",
      "- GPU CUDA (if present): ✅\n",
      "- Write permissions (reports + metrics): ✅\n",
      "- NPU detected: ✅\n",
      "- Consistency quickcheck: ✅\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
